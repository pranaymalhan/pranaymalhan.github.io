<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Portfolio</title>
    <link rel="stylesheet" href="css\style.css"> 
</head>
<body>
    <header>
        <h1>Pranay Malhan</h1>
        <h2>Data Engineer</h2>
    </header>
    <section>
        <h2>PROFILE</h2>
        <ul>
            <li>Highly experienced data engineer with over 4 years of proven track record in constructing and developing cloud data processing systems.</li>
            <li>Implemented significant data solutions, resulting in measurable business value and efficient data operations.</li>
            <li>Currently, helping Oportun make financial health effortless for everyone.</li>
        </ul>
    </section>
    <section>
        <h2>EMPLOYMENT</h2>
        <p>Data Engineer</p>
        <p>Oportun</p>
        <p>Aug 2022 - Present</p>
        <ul>
            <li>Working as a Data Engineer in Personal loan and Credit Card business segments of organization.</li>
            <li>Migrated multiple legacy processes to Databricks for leveraging lakehouse architecture.</li>
            <li>Extended SQL codes to support changing requirements for multiple business reports.</li>
            <li>Migrated SQL procedures from legacy to current database by defining query and attribute mapping, saving organization around $50k.</li>
            <li>Implemented data orchestration using Airflow to manage dependency among multiple AWS Glue jobs.</li>
            <li>Automated Jenkins monitoring process using webhook URL for sending jobs status to slack.</li>
            <li>Created multiple queries for vendor report generation on large datasets in Redshift.</li>
            <li>Leveraged Athena in Jenkins jobs for querying data stored in s3.</li>
        </ul>
        <p>Systems Engineer</p>
        <p>Tata Consultancy Services</p>
        <p>Sep 2020 – Aug 2022</p>
        <ul>
            <li>Worked in Data Engineering role for Pharmaceutical Client.</li>
            <li>Developed data solutions using PySpark in Databricks which efficiently processed terabytes of data.</li>
            <li>Wrote complex T-SQL queries and stored procedures in MS SQL Server for data analysis.</li>
            <li>Created end-to-end fully automated data pipelines using Azure data factory and ADLS.</li>
        </ul>
    </section>
    <section>
        <h2>EDUCATION</h2>
        <p>Ghaziabad, UP</p>
        <p>Ajay Kumar Garg Engineering College</p>
        <p>Aug 2016 – Sep 2020</p>
        <ul>
            <li>B. Tech in Computer Science and Engineering with 8.83 CGPA.</li>
            <li>Coursework: Databases, Algorithms, Programming Languages.</li>
        </ul>
    </section>
    <section>
        <h2>ADDITIONAL EXPERIENCE AND AWARDS</h2>
        <ul>
            <li>Azure DP-203 certified</li>
            <li>Gold badge in Python and SQL on Hackerrank.</li>
            <li>Knight on Leetcode</li>
        </ul>
    </section>
    <section>
        <h2>LANGUAGES AND TOOLS</h2>
        <ul>
            <li>Python, SQL, PySpark</li>
            <li>Databricks</li>
            <li>AWS (Glue, S3, Redshift, Athena)</li>
            <li>Azure (Data factory, ADLS)</li>
            <li>Airflow</li>
        </ul>
    </section>
</body>
</html>